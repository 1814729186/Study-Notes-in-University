# 操作系统复习

## 一.计算机系统概述

- 虚拟——把一个我物理上的实体变为若干逻辑上的对应物

- 用户态只能执行非特权指令

- 中断——来自CPU执行指令意外的事件的发生

  异常（内中断）——CPU执行指令内部的事件，如程序的非法操作码

- 中断处理过程

  - 关中断
  - 保存断点
  - 中断服务程序寻址
  - 保存现场和屏蔽字
  - 开中断
  - 执行中断服务程序
  - 关中断
  - 恢复现场和屏蔽字
  - 开中断
  - 中断返回

- 系统调用 —— 用户在程序中调用操作系统所提供的一些子功能，可视为一些特殊的公共子程序

  - 设备管理
  - 文件管理
  - 进程控制
  - 进程通讯
  - 内存管理

- 系统调用的处理需要由操作系统内核程序负责完成，要运行在核心态，用户程序可执行**陷入指令**（**访管指令**或**trap指令**）来发起系统调用，请求操作系统提供服务（主动将CPU的使用权交还给操作系统内核程序）。

  - 核心态用户态设置的目的：保证系统的稳定性和安全性，防止用户程序随意更改或访问重要的资源，影响其他进程的运行。

- 用户态转核心态的例子

  - （1）用户程序要求操作熊的服务（系统调用）
  - （2）发生一次中断
  - （3）用户程序产生了一个错误状态
  - （4）用户程序企图执行一条特权指令
  - 从核心态转向用户态由一条指令实现，这条指令也是特权指令，一般是中断返回指令。由用户态进入核心态，不仅状态需要切换，而且所用的堆栈也可能需要由用户堆栈切换到系统堆栈，但这个系统堆栈也是属于该进程的。

  

## 二.进程管理

- 涉及的指针（链接方式）
  - 执行指针
  - 就绪队列指针
  - 阻塞队列指针
- （索引方式）
  - 执行指针
  - 就绪表指针 -- > 就绪索引表
  - 阻塞表指针

- **进程**——具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。

  **线程**——CPU调度的基本单位

- 进程控制块（PCB）—— 描述进程的基本情况和运行状态，进而控制和管理进程。

  进程映像 = 程序段 + 相关数据段 + PCB

- 创建进程的实质是创建进程映像中的PCB，撤销进程的实质是撤销进程的PCB。进程映像是静态的，进程则是动态的。

- 进程的状态：

  - （1）运行态
  - （2）就绪态
  - （3）阻塞态
  - （4）创建态
  - （5）结束态

### 进程控制

- 进程创建

  - （1）为新进程分配一个唯一的进程标识符（pid），并申请创建一个空白的PCB。（可能申请失败）
  - （2）为进程分配资源。资源分配失败，则进程会进入阻塞态而非创建失败
  - （3）初始化PCB，初始化标志信息、处理机状态信息、处理机控制信息，设置进程优先级
  - （4）将其插入进程就绪队列（如果可以插入的话）

- 进程终止

  - 引起进程终止的事件：1）正常结束，2）异常结束（越界访问、非法指令等），3）外界干预（如父进程结束，子进程也会终止）
  - 操作系统通过“撤销原语”终止进程：
    - 1）检索PCB，读出相应pid的进程的状态
    - 2）若相关进程处于执行状态，终止，将CPU分配给其他资源
    - 3）将该进程的子进程终止
    - 4）将进程的全部资源归还给其父进程或者操作系统
    - 5）从队列中删除其PCB

- 进程的阻塞和唤醒

  - 阻塞原语
    - 1）找到PCB
    - 2）若其出于运行态，保护其现场，将状态转为阻塞态
    - 3）把PCB插入相应事件的等待队列，将CPU资源调度给其他就绪的进程
  - 唤醒原语
    - 1）找到等待队列中相应的PCB
    - 2）将PCB移出就绪队列，设置状态为就绪态，并将其插入就绪队列

- 进程切换

  - 切换原语
    - 1）保存上下文
    - 2）更新PCB信息
    - 3）把PCB移入相应的队列（就绪或者某个事件的等待队列等）
    - 4）从就绪队列中选择一个进程，更新其PCB
    - 5）更新内存管理的数据结构
    - 6）恢复处理机上下文

- 调度——针对于资源，是决策行为

  切换——针对于进程，是执行行为。先有资源的调度，才有进程的切换

- 进程控制块（PCB）内容
  - 1）进程描述信息：进程标识符、用户标识符（用于共享和保护）
  - 2）进程控制和管理信息：进程状态，进程优先级
  - 3）资源分配清单：内存地址空间，文件列表，使用的设备信息
  - 4）处理机相关信息：现场

### 进程通讯

- 1）共享内存

  - 基于数据结构的共享
  - 基于储存区的共享

- 2）消息队列

  - 两个原语 —— 发送消息，接收消息

- 3）管道通信

  - 两个进程之间共享一个pipe文件
  - 管道通信的进程之间必须能够完成互斥和同步的操作

  - 管道只能半双工通讯

### 线程概念

- 线程 —— 轻量级进程。

- 引入进程 —— 更好地使多道程序并发执行，提高资源利用率和系统吞吐量

  引入线程 —— 减小程序在并发执行时所付出的时间开销，提高系统的并发性能

- 线程是进程中的一个实体，是被系统独立调度的基本单位。线程不拥有系统资源，线程可以创建和撤销线程
- 线程切换的开销小于进程切换

**线程属性**

- 1）CPU调度的基本单位
- 2）多CPU中不同线程可占据不同CPU
- 3）拥有标识符和线程控制块
- 4）线程也有就绪、阻塞和运行状态
- 5）不拥有系统资源
- 6）同一进程不同线程之间共享进程的资源
- 7）同一进程不同线程之间的通信无需系统干预
- 8）同一进程的线程切换不会引起进程切换
- 9）切换线程的系统开销小于进程切换

**进程与线程区别：** ***

​	定义上：进程是系统分配资源的基本单位，线程是CPU调度的基本单位，线程是进程的一部分

- 1）从调度上来看：线程是CPU调度的基本单位，同一进程内线程的切换不会引起进程的切换。线程提高了进程的并发度
- 2）从资源来看：线程不拥有系统资源，而是共享其所属进程的资源
- 3）并发性：线程拥有更高的并发性
- 4）系统开销：（同一进程中的）线程之间切换时开销小，线程之间的通信很容易，无需操作系统的干预
- 5）地址空间和其他资源：进程的地址空间相互独立，而同一进程的线程之间资源共享
- 6）通讯方面：进程间通讯（IPC）需要进程同步和互斥手段辅助，以保证数据的一致性，而线程间可以直接读写进程数据段（如全局变量）来进行通讯

**线程的实现方式：**

- 用户级线程（用户线程库实现）

  - 由应用程序创建和管理线程，内核意识不到线程的存在。实际上是一个内核级线程上模拟运行了多个用户及线程

- 内核级线程（内核支持的线程）

  - 由操作系统内核管理线程

  - 优点：并发能力更强

    缺点：一个用户进程可能占据多个内核级线程，进程切换需要OS内核进入核心态，线程管理成本高，开销大。

**多线程模型：**

- （1）一个内核线程 - 多个用户线程
  - 优点：效率高
  - 缺点：并发性差，用户线程中只能由一个可以执行
- （2）一对一
  - 优点：并发性高
  - 缺点：进程管理的开销大
- （3）多对多（一个内核线程管理不定项个用户进程）
  - 取各家所长

**C++中用户及线程和内核级线程的创建**



### CPU调度

周转时间 = 作业完成时间 - 作业提交时间

- 调度方式：

  - 非剥夺调度方式
  - 剥夺调度方式（抢占式）

- 调度算法

  - （1）先来先服务 FCFS （非抢占式）

  - （2）短作业优先  SJF，短进程优先 SPF

    - 对长作业不利
    - 未考虑优先级
    - 由于运行时间不可预先知道，实际不能完全保证做到短作业优先

  - （3）优先级调度算法

    是否抢占

    - （1）非剥夺式
    - （2）剥夺式

    优先级分类

    - （1）静态优先级
    - （2）动态优先级

    一般来说，优先级有：1）系统进程 > 用户进程。2）交互型进程 > 非交互型进程，3）IO型进程 > 计算型进程

  - （4）高响应比优先调度算法

    - 响应比Rp = (等待时间 + 要求服务时间) / 要求服务时间
      - 1）有利于短作业（响应比增加块）
      - 2）克服长作业的饥饿状态

  - （5）时间片轮转调度算法

    - 时间片不能过大或者过小

  - （6）多级反馈队列

    - 多个就绪队列，优先级不同
    - 不同队列不同的时间片长度，越往后越高，最后一个队列要保证完全执行完。
    - 每级队列之内采用FCFS调度
    - 一个进程在某一级队列未完成执行，则自动调整进入下一级队列
    - 因为资源阻塞后的程序在进入就绪态后会优先进入高级队列

### 进程同步

- 临界资源：一次仅允许一个进程使用的资源

  临界区

- **同步** —— 直接制约关系，是指为完成某种任务而简历的两个或者多个进程，这些进程因为需要在某些位置上协调他们的工作次序而等待、传递信息所产生的制约关系。进程同步实质在于进程之间的合作

  **互斥** —— 间接制约关系，禁止两个进程同时访问临界资源

- 同步机制的**准则**

  - （1）空闲让进
  - （2）忙则等待
  - （3）有限等待：保证能在有限时间内进入临界区
  - （4）让权等待：进程不能进入临界区则应立即释放处理器

- **实现临界区互斥的方法**

  - （1）单标志法：（循环检测，类似于自旋锁）
  - （2）双标志先检查法：（先检查对方是否进入临界区）
  - （3）双标志后检查法
  - （4）Peterson‘s Algorithm：单标志 + 双标志后检查。谦让型临界区访问

- 硬件实现方法

  - 中断屏蔽（关中断后不会发生进程切换）

  ```c++
  关中断;
  临界区;
  开中断;
  ```

  - 硬件指令（下属指令为硬件实现的原子操作，不会被中断）-可能导致饥饿现象
    - TestAndSet指令 - 读出指定标志后，将标志设置为真
    - Swap指令

- 信号量

  - wait(S)和signal(S) （P、V操作）
  - 信号量可用于实现同步和互斥，利用信号量可以实现前驱关系

- 管程

  - 管程 —— 用于抽象表示系统资源并对访问系统资源的进程进行调度的一组程序
  - 组成
    - （1）管程名
    - （2）共享数据结构说明
    - （3）对该数据结构进行操作的一组过程
    - （4）对局部于管程内部的共享数据设置初始值的语句
  - 管程把对共享资源的操作封装起来，每次仅允许一个进程进入管程，从而实现进程互斥

  ```C++
  //管程x
  x.wait();	//当x对应的条件不满足时，正在调用管程的进程调用x.wait()将自己插入x条件的等待队列，并释放管程
  x.signal();	//x对应的条件发生了变化，则调用x.signal唤醒一个因x条件而阻塞的进程
  ```

- 经典同步问题

  - 生产者消费者问题
  - 读写问题
  - 哲学家进餐问题
  - 吸烟者问题

### 死锁

- 三个概念：
  - 死锁：相互等待的僵局
  - 饥饿
  - 死循环
- 死锁产生的必要条件
  - （1）互斥条件
  - （2）不剥夺条件
  - （3）请求并保持条件
  - （4）循环等待条件
- 银行家算法

- 死锁解除
  - （1）资源剥夺法
  - （2）撤销进程法
  - （3）进程回退法





## 三.内存管理

### （一）内存管理的**功能**：

- **内存空间的分配与回收**
- **地址转换**
- **内存空间的扩充**
- **储存保护**

1.内存的装入模块在**装入内存时**，有以下三种方式：

- 1）**绝对装入**
- 2）**可重定位装入**（静态重定位）
  - 可变的起始地址，但需要一次性完成全部空间的分配，运行期间不能再内存中移动，也不能再申请内存空间
- 3）**动态运行时装入**（动态重定位）
  - 不转换相对地址，而是在执行时采转换为绝对地址（需要一个**重定位寄存器**），
  - 可以将程序分配到不连续的存储区中，在程序运行之前可以只装入它的部分代码即可投入运行，在运行期间，根据动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。

2.逻辑地址空间、物理地址空间

3.内存保护的方法

- 1）CPU中设置一对上下限寄存器
- 2）采用重定位寄存器（或基址寄存器）和界地址寄存器（又称限长寄存器），界地址寄存器储存**逻辑地址**的最大值

### （二）多道程序环境中的内存扩充 —— 覆盖与交换

- **覆盖**

  思想：把用户空间分为一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段，首先将要访问的段放入覆盖区，其他段放在外村中，在需要调用前，系统将其调入覆盖区，替换掉原有的段

  特点：一个进程的部分信息装入主存后就可以运行

- 交换

  思想：将出于等待状态的程序（或者低优先级程序）从内存中移到辅存（换出），把空间腾出来让给就绪的程序（换入）

- 交换技术用于不同作业之间，覆盖技术用于同一作业

### （三）连续分配管理方式

- 1.单一连续分配
  - 简单，无外部碎片，可以采用覆盖技术；但只能用于单用户、单任务OS，有内部碎片，储存器的利用率低。
- 2.固定分区分配
  - 将内存空间划分为若干固定大小的块，每个分区只装入一道作业
- 3.动态分区分配
  - 在进程装入内存时，根据进程的大小动态地简历分区，并使分区的大小正好适合进程的需要
- 分配策略：
  - （1）首次适应算法
  - （2）最佳适应算法
  - （3）最坏适应算法
  - （4）邻近适应算法（循环首次适应算法）

### （四）非连续分配管理方式

- 存储密度低于连续分配，但空间利用率高

#### 1.基本分页存储管理方式

- 将**主存空间划分为大小相等且固定的块**、块相对较小，作为主存的基本单位。每个进程以块为 单位进行划分，进程在执行时，以块为单位诸葛申请主存中的块空间

- 分页管理不会产生外部碎片（但有很小的内部碎片）

- 进程中 —— 页

  内存中 —— 页框、页帧

  外存中 —— 块

**页的地址结构（**位数取决于页大小）：

​	页号P | 页内偏移量W

**页表**

- 便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程创建一张页表，它记录页面在内存中对应的物理快好，页表一般存放在内存中
- 每个进程对应一个页表

**基本地址变换机构**

- 访存需要两次：（1）查页表获得块号，（2）取数据

- 页表寄存器PTR（页表起始地址F | 页表长度 M） —— 存放于PCB中
- 变换过程：
  - （1）逻辑地址（页号p | 页内偏移量W）
  - （2）页表寄存器（页表起始地址F | 页表长度 M）
  - （3）比较页表长度M和页号P，若P更大则发生越界中断
  - （4）用F+P为地址找到相应的页表项，获得块号b
  - （5）物理地址 E = b * L + W（L是块大小）

地址变换过程是硬件自动完成的

**具有快表的地址变换机构**

- **快表TLB** -- 告诉缓冲储存器，又称项链储存器（TLB），用于存放页表若干表项，加速地址变换过程。相对应的主表中的页表称为慢表

- 有些处理及设计为快表和慢表同时进行查找
  - （1）CPU给出逻辑地址，由硬件进行地址转换，将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较（并行比较）
  - （2）若找到匹配的页号，说明索要访问的页表项在快表中，则直接读出相应的页框号，与偏移量拼接形成物理地址（一次访存即可获取目标数据）
  - （3）为占到匹配的页号，则访问主存中的页表，读出页表项后，将其存入快表，以便再次访问

- 单机页表的问题
  - （1）**页表必须连续存放**，因此页表很大时需要占用很多个连续的页框
  - （2）没有必要让整个页表常驻内存，进程具有局部性

**两级页表**

- 解决需要连续存放的问题
- 页表的大小也按照页大小来进行划分，顶级页表只占用一个页的大小
- 逻辑地址 （一级页号 | 二级页号 | 页内偏移）
- 访存次数 = 页表级数 + 1（不考虑TLB快表）

#### 2.基本分段存储管理方式

- 分页管理方式是从计算机角度出发，用于提高内存利用率，提升计算机性能的。
- 分段管理方式则考虑程序员，方便编程、信息保护和共享、动态增长及动态链接等多方面的需要

（1）分段

- 段式管理方式按照用户进程中的自然段划分逻辑空间

- 每段从0开始编制，段内连续，整个作业的地址空间是二维的
- 逻辑地址 （段号 | 段内偏移）
- 页式系统中，逻辑地址的页号和页内偏移对用户是透明的，但段式系统中，短号和段内偏移量必须由用户显示提供（由编译程序完成）

（2）段表

​	每个进程都有一张逻辑空间与内存空间映射的段表，其中每个段表项对应进程的一段，段表项记录该段在内存中的始址和长度

​			**段号（隐含） | 段长 | 本段在主存的始址**

配置段表后，执行中的进程可以通过查找段表，找到每段所对应的内存区。段表用于实现从逻辑地址到物理内存区的映射

（3）地址变换机构

- 1）逻辑地址A （段号S | 偏移量 W）（一般是二进制前几位为段号）

- 2）比较段号S和段长度M，若S>=M则产生越界中断
- 3）段表中段号S对应的段表项地址 = 段表首址F + 段号S * 段表项长度，取出段长C，若M >= C则发生越界中断
- 4）取出段的始址b，物理地址 E = b + W

（4）段的共享与保护

- 分段系统中，段的共享是通过两个作业的段表中相应表象指向被共享的段的共一个物理副本来实现的。不能修改的代码和数据可以直接共享，能修改的则需要引入互斥同步后才能共享

#### 3.段页式管理方式

- 页式管理能够有效提高内存利用率，而分段式储存管理能反映程序的逻辑结构并有利于段的共享

- 段页式逻辑地址结构

  ​	段号S | 页号 P | 页内偏移量W

- 一个进程中，段表只能有一个，而页表能由多个。段表表项储存段长和页表起始地址，一个段对应一个页表

## 三.虚拟内存

虚拟内存特征：

​	（1）**多次性**：程序无须在作业运行时一次性全部装入内存，而被允许分成多次调入内存运行

​	（2）**对换性**：无需常驻内存，经常换入换出

​	（3）**虚拟性**：从逻辑上扩充内存的容量，使用户所看到的内存容量远大于实际内存容量

虚拟内存技术的实现：	（必须离散分配）

三种方式：

- 请求分页式
- 请求分段式
- 请求段页式

硬件支持

- 一定容量的内存和外存
- 页表机制（或段表机制）
- 中断机制，缺页中断
- 地址变换机构
- +请求调页、页面置换功能

### （一）.请求分页管理方式：

#### 1.页表机制

虚拟内存中的页表项

​	**| 页号 | 物理块号| 状态位P | 访问字段A | 修改位 | 外存地址 |**

访问字段用于替换算法

#### 2.缺页中断机构

- 所访问的页面不在内存中时，会产生一个缺页中断。请求操作系统将所缺的页调入内存。

- 将缺页的进程阻塞（调页完成后唤醒），若内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中相应的页表项，若此时内存中没有空闲块，则要淘汰某页。若淘汰页在内存期间被修改过，则要将其写回外存。

- 缺页中断作为中断。也要经历：保护CPU环境、分析中断原因、转入缺页中断处理程序、恢复CPU环境等几个步骤。但与中断相比：
  - （1）在执行指令期间，而非一条指令执行完成后产生和处理的中断信号，属于内部中断
  - （2）一条指令在执行期间，可能产生多次缺页中断

#### 3.地址变换机构

![011](.\resources\011.png)



### （二）页面置换算法

#### 1.最佳OPT置换算法

- 最佳置换算法选择的是选择的时被淘汰的页面是以后永远不适用的页面，或者是在最长时间不再被访问的页面
- 不可预知，无法实现

#### 2.先进先出（FIFO）页面置换算法

- 优先淘汰最早进入内存的页面（即在内存中主流时间最久的页面）
- （把调入的页根据先后次序连接成队列）

#### 3.最近最久未使用（LRU）置换算法

- 记录页面自上次被访问以来经历的时间，淘汰页面时选择现有页面中的最大值予以淘汰

#### 4.时钟（clock）置换算法

- 为每一个页面设置一个使用位，装入主存时设置为1，当页面再次被访问时，使用位被置为1。当该页再次被访问时，使用位置为1.
- 设置一个循环指针，缺页时从前向后依次滑动（列表循环），将遇到的访问位为1的置为0，将遇到的0置换出来

置换算法可能出现抖动现在想。

## 文件结构

Linux索引文件结构







# 计算机网络复习

## 一、传输层

- 传输层功能

——不同进程之间的逻辑通信、复用和分、差错检测、提供TCP、UDP两种协议

- 端口

  让应用层各种应用进程将其数据通过端口向下交付给传输层，以及让传输层知道应当将其报文段中的数据向上通过端口交付给应用层相应的进程。端口时传输层的服务访问点。

- 款口号

  - 常见端口号：HTTP ： 80，HTTPS：443，SMTP：25，FTP：31

- 套接字

  - Socket = （IP地址 ： 端口号）

### UDP数据报：

- UDP只在IP的服务至上添加了两个最基本的服务：复用分佣、差错检测
- UDP首部有8字节的开销
- UDP支持一对多，多对多，多对一等
- UDP不保证可靠性交付
- UDP时面向报文的

UDP在接受上层的报文后，不拆分，直接添加首部后交付下层。（ip层可能会分片）。反之从下层收到的报文，去除首部后会直接交付上层。

##### UDP首部格式

​	源端口(16) | 目的端口(16) | UDP数据报长度(16)(包含首部) | 校验和(16)

- 不需要回信时，源端口可以全部置0



### TCP协议

- 面向连接、一对一
- 提供可靠的交付服务，无差错，不丢失、不重复、有序
- 全双工通讯
- TCP面向字节流（将数据视作无结构的）

TCP报文段：源端口 | 目的端口 | 序号 | 确认号 | 数据偏移 | 保留 | 标识符 | 窗口 | 校验和 | 紧急指针 | 选项 | 填充

**TCP的可靠传输**：**校验、序号、确认、重传**

- 超时或者冗余ACK都会导致重传

#### TCP流量控制

- TCP提供流量控制服务来消除发送方（发送速度太快）使接收方缓存区溢出的可能性。可以说流量控制是一个发送和接收方的速度匹配服务
- TCP提供一种基于滑动窗口协议的流量控制机制
  - 通信过程中，接收方根据自己接受缓存的大小，动态地调整发送方的发送窗口的大小（TCP首部中的窗口字段），这称为**接收窗口rwnd**
  - 发送方根据其对当前网络拥塞程序的估计而确定的窗口值，这称为**拥塞窗口cwnd**
  - 发送方的发送窗口实际大小取rwnd和cwnd的最小值。一般来说，rwnd取值为接收方为保证不溢出能够接收的最多报文数量

#### TCP拥塞控制

- 拥塞控制是为了防止过多数据注入网络，保证网络中的路由器或者链路不致过载。端点并不了解拥塞的发生情况，对通信连接的端点来说，拥塞往往表现为通信时延的增加
- 拥塞控制是让网络能够承受现有的网络载荷，是一个全局性的过程，设计所有主机、所有路由器，以及降低网络传输性能有关的所有因素。
- 拥塞控制和流量控制都是通过控制发送方发送数据的速率来达到控制效果的。

接收窗口rwnd，拥塞窗口cwnd

- 慢开始

  - 先令窗口cwnd = 1（一个最大报文段长度），每经过一个传输轮次（往返时延RTT），cwnd就会增大。增大到慢开始门限值ssthresh就改用拥塞避免算法

- 拥塞避免

  - cwnd每一轮增大1

- 网络拥塞的处理

  - 出现网络拥塞将ssthresh设置为当前cwnd的一半，cwnd设置为1，重新开始慢开始和拥塞避免

- 快重传和快恢复

  - 快重传：连续收到三个重复ACK，则直接重传尚未收到的报文段

  - 快恢复：连续收到三个冗余ACK，将ssthresh设置为当前cwnd的一半（预防网络拥塞），然后将cwnd设置为ssthresh的一半，执行拥塞避免算法

#### 补充：

##### **1.怎样在UDP上实现可靠性传输**

可以在应用层着手实现与TCP类似的可靠机制——**确认机制、重传机制、窗口确认机制**

发送方：**包的分片、包的确认、包的重传**

接收方：**包的调序、包的序号确认**

目前有如下开源库实现了udp的可靠传输：RUDP，RTP，UDT

### RUDP

​	RUDP 提供一组数据服务质量增强机制，如**拥塞控制的改进**、**重发机制**及**淡化服务器算法**等，从而在包丢失和网络拥塞的情况下， RTP 客户机（实时位置）面前呈现的就是一个高质量的 RTP 流。在不干扰协议的实时特性的同时，可靠 UDP 的拥塞控制机制允许 TCP 方式下的流控制行为。

### RTP

​     实时传输协议（RTP）为数据提供了具有实时特征的端对端传送服务，如在组播或单播网络服务下的交互式视频音频或模拟数据。应用程序通常在 UDP 上运行 RTP 以便使用其多路结点和校验服务；这两种协议都提供了[传输层协议](https://so.csdn.net/so/search?q=传输层协议&spm=1001.2101.3001.7020)的功能。但是 RTP 可以与其它适合的底层网络或传输协议一起使用。如果底层网络提供组播方式，那么 RTP 可以使用该组播表传输数据到多个目的地。

​	RTP 本身并没有提供按时发送机制或其它服务质量（QoS）保证，它依赖于底层服务去实现这一过程。 RTP 并不保证传送或防止无序传送，也不确定底层网络的可靠性。 RTP 实行有序传送， RTP 中的序列号允许接收方重组发送方的包序列，同时序列号也能用于决定适当的包位置，例如：在视频解码中，就不需要顺序解码。

### UDT

​     基于UDP的数据传输协议（UDP-basedData Transfer Protocol，简称UDT）是一种互联网数据传输协议。UDT的主要目的是支持高速广域网上的海量数据传输，而互联网上的标准数据传输协议TCP在高带宽长距离网络上性能很差。顾名思义，UDT建于UDP之上，并引入新的拥塞控制和数据可靠性控制机制。UDT是面向连接的双向的应用层协议。它同时支持可靠的数据流传输和部分可靠的数据报传输。由于UDT完全在UDP上实现，它也可以应用在除了高速数据传输之外的其它应用领域，例如点到点技术（P2P），防火墙穿透，多媒体数据传输等等。

##### 2.在浏览器中输入一个url后执行的事件

**（1）域名解析（DNS解析）**

浏览器缓存 -- > 操作系统缓存 -- > 路由器缓存 -- > ISP DNS --> 根域名服务器查询

**（2）调用connect()发起TCP的三次握手**

**（3）浏览器向wed服务器发起HTTP请求**

- 应用层封装好了请求报文，交付传输层。

​		请求报文结构

​			请求报头：请求方法，目标地址，http版本，协议等

​			请求主体：其他参数

- 传输层封装

  将数据拆分为报文段，添加首部（包括序号、校验和等等），提交下一层

  （建立连接前会执行三次握手操作）

- 网络层封装

  将数据打包，添加ip首部，查找路由地址

  判断目标地址与当前地址是否出于同一网络中，是的话根据mac地址发送，否则使用路由表查找下一跳的地址，使用ARP协议查询mac地址

  （ARP广播获得网关mac地址等，接收方回消息是单播）（OSI模型中，ARP位于链路层，但在TCP/IP中，它位于网络层）

- 链路层（以太网协议）

  将数据分为以帧为单位的数据包，每一帧包含：标头（发送者，接收者，数据类型）、数据

- 物理层

**（4）服务器处理请求**

​	接受 TCP 报文后，会对连接进行处理，对HTTP协议进行解析（请求方法、域名、路径等），并且进行一些验证：

- 验证是否配置虚拟主机

- 验证虚拟主机是否接受此方法

- 验证该用户可以使用该方法（根据 IP 地址、身份信息等）

**重定向**

​	假如服务器配置了 HTTP 重定向，就会返回一个 301永久重定向响应，浏览器就会根据响应，重新发送 HTTP 请求（重新执行上面的过程）。

**URL 重写**

​	然后会查看 URL 重写规则，如果请求的文件是真实存在的，比如图片、html、css、js文件等，则会直接把这个文件返回。

​	否则服务器会按照规则把请求重写到 一个 REST 风格的 URL 上。

​	然后根据动态语言的脚本，来决定调用什么类型的动态文件解释器来处理这个请求。

​	以 PHP 语言的 MVC 框架举例，它首先会初始化一些环境的参数，根据 URL 由上到下地去匹配路由，然后让路由所定义的方法去处理请求。

**（5）服务器HTTP响应**

在HTTP里，有请求就会有响应，哪怕是错误信息。这里我们同样看下响应报文的组成结构：

- 报文首部
- 空行
- 报文主体

**（6）浏览器接受响应**

**（7）断开TCP连接（不是长连接的话）-- 四次挥手**

**（8）浏览器解析HTML以及其他资源文件，显示在屏幕上**

# 其他

#### 1.https能否防范中间人攻击

中间人攻击：中间人篡改报文内容

https可以通过**CA认证体系**来防止中间人攻击。

权威认证机构：在 CA 认证体系中，所有的证书都是由权威机构来颁发，而权威机构的 CA 证书都是已经在操作系统中内置的，我们把这些证书称之为`CA根证书`：

签发证书：我们的应用服务器如果想要使用 SSL 的话，需要通过权威认证机构来签发`CA证书`，我们将服务器生成的公钥和站点相关信息发送给`CA签发机构`，再由`CA签发机构`通过服务器发送的相关信息用`CA签发机构`进行加签，由此得到我们应用服务器的证书，证书会对应的生成证书内容的`签名`，并将该`签名`使用`CA签发机构`的私钥进行加密得到`证书指纹`，并且与上级证书生成关系链。

当客户端(浏览器)做证书校验时，会一级一级的向上做检查，直到最后的`根证书`，如果没有问题说明`服务器证书`是可以被信任的。

客户端(浏览器)又是如何对`服务器证书`做校验的呢，首先会通过层级关系找到上级证书，通过上级证书里的`公钥`来对服务器的`证书指纹`进行解密得到`签名(sign1)`，再通过签名算法算出服务器证书的`签名(sign2)`，通过对比`sign1`和`sign2`，如果相等就说明证书是没有被`篡改`也不是`伪造`的。

这样通过证书的认证体系，我们就可以避免了中间人窃取`AES_KEY`从而发起拦截和修改 HTTP 通讯的报文。

#### 2.https能否防范DNS劫持

可以，通过CA认证体系

###### 攻击HTTPS连接有多难？

对HTTPS连接的攻击通常分为3类：
• 通过密码分析或其他协议弱点来破坏HTTPS连接的质量。
• 攻破客户端计算机，例如将恶意根证书安装到系统或浏览器信任库中。
• 通常通过操纵或破坏证书颁发机构来获取主要浏览器信任的“流氓”证书。
这些都是可能的，但对于大多数攻击者而言，这些攻击都非常困难并且需要大量费用。重要的是，它们都是有针对性的攻击，并且不能随时对任何连接到任何网站的用户执行。相比之下，普通的HTTP连接可以被网络连接中涉及的任何人轻易拦截和修改，因此攻击可以大规模且低成本地进行。

沃通CA提供HTTPS证书，支持Windows、安卓、iOS、JDK以及Firefox、Chrome等各类浏览器、操作系统和移动终端，为用户与服务器之间建立加密连接，保护数据传输安全、防止中间人攻击的同时，帮助服务器更有效地防止DNS欺骗等安全威胁。

#### 3.为什么要分段分页

分段：

分页：

#### 4.怎么解决C++符号表冲突，C呢

C++使用命名空间

C可以使用宏定义

```c
#define func LIBB_func47
```

#### 5.设计模式六大原则



#### 6.leetcode113

#### 

#### 7.之字形打印二叉树

#### 8.拥塞控制



#### 9.static位置，初始化时间



#### 10.extern原理



#### 11.为什么浮点数不能直接比较



#### 12.get和post的区别



#### 13.osi七层合并为五层，合并了哪些。为什么合并？



#### 14.抛硬币，先手赢概率



#### 15.全排列不带重复，全排列带重复



#### 16.leetcode53，数组会重复M次，空间复杂度，时间复杂度都要最优



#### 17.项目中用到的设计模式



